{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d23b54",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lesson 24: Building Something Good\n",
    "\n",
    "DS2500 April 11, 2023\n",
    "Matt Higger\n",
    "\n",
    "### Admin:\n",
    "- regrade requests can only be submitted until weds april 12 @ 11:59\n",
    "    - (of course, we'll process anything you've already submitted)\n",
    "- peer feedback for presentations\n",
    "    - [its a google form](https://forms.gle/VY1hXreeksRn4mkJ6)\n",
    "    - its 1% of your presentation grade to grade 22 presentations (11 per class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d142903f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TRACE\n",
    "- TRACE feedback helps me be a better teacher for you all.\n",
    "- TRACE feedback helps NU identify strong / weak teachers.\n",
    "\n",
    "Please take a few minutes to give feedback about what worked and what didn't.  (accesible via myNortheastern)\n",
    "\n",
    "### To encourage you all to participate:\n",
    "- .5 participation across all sections  → additional 1 ICA drop\n",
    "- .7 participation across all sections → additional 2 ICA drop\n",
    "- .85 participation across all sections  → additional 2 ICA drop & 1 HW late day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa48c27",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Technology, more than any other factor, has re-defined the human experience over the past 30 years  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e08f19",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Our new robot overlord seems to agree:\n",
    "\n",
    "<img src=\"https://i.ibb.co/Vw0xMQR/chat-gpt-human-experience.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4017c800",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ethics in Data Science (outline)\n",
    "\n",
    "- Technology has re-defined the human experience\n",
    "    - technology influences your personal life\n",
    "    - privacy is quaint\n",
    "    - tech can exaggerate discrimination\n",
    "    \n",
    "- How do we build data science which has a positive impact on the world?\n",
    "    - consent\n",
    "    - beneficence\n",
    "    - justice\n",
    "    \n",
    "## Heads up:\n",
    "- in the first section I hope to alarm you\n",
    "- in the second I hope to share some ideas which help you build positive technology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393e5799",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Technology influences your personal life\n",
    "\n",
    "<img src=\"https://i.ibb.co/7rMdG21/PXL-20220508-215047787.jpg\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161560cf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Privacy is quaint\n",
    "\n",
    "<img src=\"https://i.ibb.co/D8s1qXF/Screenshot-from-2023-04-10-13-58-57.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e58492",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Privacy is quaint\n",
    "\n",
    "<img src=\"https://i.ibb.co/K5XmT8B/nu-lost-ssn.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd04f347",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Privacy is quaint\n",
    "\n",
    "<img src=\"https://i.ibb.co/mGrp68V/Equifax-settle.jpg\" width=700>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d9c582",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Privacy is quaint\n",
    "\n",
    "## A bit of data identifies most people\n",
    "- without the name or a pseudonym, 87% of US population is uniquely identified by ZIP code, gender, and date of birth [1]\n",
    "    \n",
    "- 95% of population is uniquely identified by four observations of their rough location at a given time [2]\n",
    "\n",
    "[1] \"Simple Demographics Often Identify People Uniquely\", L Sweeney, 2000\n",
    "\n",
    "[2]  \"Unique in the crowd: The privacy bounds of human mobility\", YA De Montjoye, et al., 2013"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b272c944",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Privacy is quaint\n",
    "\n",
    "## Data can live for a long time and be re-used for purposes other than initially intended.\n",
    "The Golden State Killer was [caught because his family members submitted DNA](https://www.latimes.com/california/story/2020-12-08/man-in-the-window) many years after the crimes were committed.\n",
    "\n",
    "- What information is in DNA?\n",
    "- Can a family member give access to each others information?\n",
    "- What constitutes fair DNA use?\n",
    "    - Insurance agencies adjusting coverage prices\n",
    "    - Admissions / Hiring using DNA to predict success (e.g. “Brave New World”)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a9340f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tech can exaggerate disrimination 1\n",
    "\n",
    "COMPAS: predict a potential parolee's likelihood to reoffend \n",
    "    \n",
    "    “blacks are almost twice as likely as whites to be labeled a higher risk but not actually re-offend,”\n",
    "\n",
    "### source\n",
    "\n",
    "[\"Machine Bias\" -Julia Angwin](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17807642",
   "metadata": {},
   "source": [
    "# Tech can exaggerate disrimination 2\n",
    "\n",
    "Amazon's recruiting algorithm: \n",
    "\n",
    "     It penalized resumes that included the word “women’s,” as in “women’s chess club captain.” \n",
    "\n",
    "### source\n",
    "\n",
    "[\"Amazon scraps secret AI recruiting tool that showed bias against women\" -Dastin](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bafea3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tech can exaggerate disrimination\n",
    "\n",
    "\n",
    "\"So can robots - and, by extension, other types of technologies - be racist? Of course they can. Robots designed in a world drenched in racism will find it nearly impossible to stay dry. To a certain extent, they learn to speak the colored language of their human parents - not only programmers but all of us online who contribute to \"naturally occurring\" data sets on which AI learn. Just like diverse programmers, Black and Latinx police officers are known to engage in racial profiling alongside their White colleagues. (…)\n",
    "\n",
    "One's individual racial identity offers no surefire isolation from the prevailing ideologies. There is no need to identify \"giggling programmers\" self-consciously seeking to denigrate one particular group as evidence of discriminatory design.  Instead, so much of what is routine, reasonable, intuitive, and codified\n",
    "reproduces unjust social arrangements, without ever burning a cross to shine light on the problem.\"\n",
    "\n",
    " -\"Race After Technology: Abolitionist tools for the new Jim code\", Ruha Benjamin, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619fae33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In Class Activity 1:\n",
    "Complete the “judge” task (see top tab) at [https://www.moralmachine.net/](https://www.moralmachine.net/) (respond in text)\n",
    "\n",
    "- Which features do you deem most important when choosing how the car should respond?\n",
    "- Who (and how) should make decision about how the car reasons in life / death situations?\n",
    "- What conflicts of interest exist for driverless car manufacturers which may hinder them from making ethical decisions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a0cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f44bf76a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to make Good tech\n",
    "- heart\n",
    "- head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90b1fe2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to make Good tech (heart)\n",
    "\n",
    "<img src=\"https://st2.depositphotos.com/1016225/7125/i/950/depositphotos_71256557-stock-photo-standing-on-soapbox.jpg\" width=200>\n",
    "\n",
    "- where appropriate: speak up\n",
    "\t- we are the technology experts, the responsibility to ensure tech is Good is largely ours\n",
    "\t- vote\n",
    "\n",
    "- much of the harm tech does is unintentional via ignorance\n",
    "\t- seek out and listen to people with very different ideas & beliefs than you\n",
    "\n",
    "\t- the people who make technology should represents the group it impacts\n",
    "\t\t- and technology impacts everyone ...\n",
    "\n",
    "- choose a career which explicitly aims to be good\n",
    "\t- going to advertise cigarettes to children will make it difficult to have a positive impact\n",
    "\t\t- your context surely shapes who you are ... but you can also shape what your context is\n",
    "\n",
    "- follow your heart\n",
    "\t- though one can’t know their impact with certainty, intentions count\n",
    "        - (intent, not impact, may be all that counts in terms of your own character)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cf64c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to make good tech (head)\n",
    "\n",
    "### Informed Consent\n",
    "- protecting the autonomy of all people (…) and allowing for informed consent. (…)\n",
    "\n",
    "### Beneficence: \n",
    "- (…) maximizing benefits for the research project and minimizing risks to the research subjects;\n",
    "\n",
    "### Justice:\n",
    "- ensuring reasonable, non-exploitative, and well-considered procedures are administered fairly — the fair distribution of costs and benefits to potential research participants — and equally\n",
    "\n",
    "###### source\n",
    "based on the “Belmont Report” (1979) and \"Beyond the Belmont Principles: Ethical Challenges, Practices, and Beliefs in the Online Data Research Community\" (2016).  \n",
    "\n",
    "This, and the slides which follow on the topic, were originally created by [Piotr Sapiezynski](https://www.sapiezynski.com/), I have modified a bit from the original source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e77cd2c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Informed Consent\n",
    "\n",
    "- some users are forced into a data product without being able not to consent\n",
    "    - proctoring software for university exams\n",
    "    \n",
    "- consent is not informed when the subjects can’t fully understand the consequences. \n",
    "    - does anybody read terms and conditions to completion?\n",
    "    - what do you really consent to when using a FaceSwap or Oldify app? (secondary uses)\n",
    "    - a street photographer gets consent to take a picture: can it be used to train a face generator?\n",
    "    \n",
    "- how to ask for consent when scraping? \n",
    "    - For example: projects that do item recommendation based on user reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a8e206",
   "metadata": {},
   "source": [
    "# Beneficence\n",
    "\n",
    "\"Researchers should have the welfare of the research participant as a goal of any clinical trial or other research study\"\n",
    "\n",
    "### Beneficence standards:\n",
    "\n",
    "- “Do No Harm”\n",
    "    - Under no circumstances should a product harm an individual\n",
    "    - Ex: This self-driving car should never harm an individual\n",
    "\n",
    "- “Maximize benefits and minimize possible harms”\n",
    "    - The potential benefits of a product should outweigh the potential harms\n",
    "    - Ex: This self driving car should harm fewer individuals than the car it replaces\n",
    "\n",
    "### Uncertainty: \n",
    "- can we always measure all our possible benefits / harms before tech adoption?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19454bfb",
   "metadata": {},
   "source": [
    "# Justice\n",
    "\n",
    "challenges to equal distribution of risks and benefits\n",
    "\n",
    "\n",
    "### ML fits a model to data ... but the data itself can be biased\n",
    "\n",
    "- natural language AIs trained on text found on the internet\n",
    "     - Online activity is more white, affluent, educated, male, and younger than general people\n",
    "\n",
    "- Data describing about human decisions encodes human biases:\n",
    "    - predictive policing [1]\n",
    "    - Looking for CVs similar to current tech employees’ will replicate bias [2-3] \n",
    "    - Predicting house price based on current prices propogates bias in current evaluations (see hw)\n",
    "\n",
    "##### source\n",
    "\n",
    "1. \"To predict and serve?\" K Lum, W Isaac, 2016\n",
    "1. \"Automating Inequality\" V Eubanks, 2018\n",
    "1. \"Amazon ditched AI recruiting tool that favored men for technical jobs\" Reuters, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1bae28",
   "metadata": {},
   "source": [
    "# Data Science Ethical Questionnaire\n",
    "\n",
    "### Consent\n",
    "- what data is collected\n",
    "- how does the tech ask for user's consent?\n",
    "- what (if any) are the secondary data uses\n",
    "\n",
    "### Beneficence\n",
    "- what good / bad does this technology do?\n",
    "    - how can I maximize this good (or minimize the bad)\n",
    "- how will the product affect the people who don’t use it?\n",
    "\n",
    "### Justice \n",
    "- who will benefit from using our product and who might get hurt? \n",
    "- who is over/under represented in my data and how will it affect the product?\n",
    "- does the product work equally well for different types of users?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b702f34",
   "metadata": {},
   "source": [
    "# In Class Assignment 2\n",
    "\n",
    "Working in groups of no more than 20, create a common google doc which analyzes the ethical impacts of a particular technology.  Please copy and follow the instructions from [this report template](https://docs.google.com/document/d/1ebssNDGWf-wCW9_eQsBNMNnGHfZ6A3jT2L9HDRfEdhQ/edit?usp=sharing).  See the instructions on [this piazza post](https://piazza.com/class/lbxsbawi9yq2f9/post/431) to form groups.\n",
    "\n",
    "When complete your group may be asked to offer a brief (90 second) report to the class at large.  \n",
    "- Questions, additions and comments from all class members welcome.\n",
    "- be sure to have a member ready and willing to give the 90 second pitch\n",
    "    - good practice for the presentations!\n",
    "    \n",
    "We list a few example technologies below, though you're welcome to use another if you think it raises sufficient ethical concerns:\n",
    "- [apple watch automatically calls 911](https://www.nytimes.com/2023/02/03/health/apple-watch-911-emergency-call.html)\n",
    "- [proctorio](https://proctorio.com/)\n",
    "- [hirevue](https://hirevue.com)\n",
    "- [leetcode interview](https://leetcode.com/interview/)\n",
    "- chatgpt\n",
    "- predicting policing\n",
    "- automated hiring systems\n",
    "- facebook's news feed algorithm (or any other media sorting in a scrolled page)\n",
    "- amazon's facial recognition software (rekognition)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
